{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "destroyed-washington",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import pipeline, ensemble\n",
    "import os\n",
    "\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "#from skimage import data\n",
    "#from skimage import transform\n",
    "#from skimage import img_as_float\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "subtle-composition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished converting and padding data\n",
      "Split Complete! Train Size: (1780, 173) Validation Size: (594, 173) Test Size: (594, 173)\n"
     ]
    }
   ],
   "source": [
    "# File Reading and Splitting\n",
    "\n",
    "# Read files\n",
    "data = []\n",
    "labels = []\n",
    "longest_sample_length = 0\n",
    "\n",
    "for root, dirpath, files in os.walk(\"Spectrograms\"):\n",
    "        for folder in dirpath:\n",
    "            for r, d, files_in_folder in os.walk(os.path.join(\"Spectrograms\", folder)):\n",
    "                for f in files_in_folder:\n",
    "                    path = os.path.join(root, folder, f)\n",
    "                    d = np.load(path)\n",
    "                    \n",
    "                    \n",
    "                    if len(d[1]) > longest_sample_length:\n",
    "                        longest_sample_length = len(d[1])\n",
    "                    \n",
    "                    data.append(d)\n",
    "                    labels.append(folder)\n",
    "                    \n",
    "\n",
    "data_new = []\n",
    "for i in range(len(data)):\n",
    "    d = data[i][1]\n",
    "    num_samp = longest_sample_length // len(d)\n",
    "    remainder = longest_sample_length % len(d)\n",
    "    \n",
    "    temp = []\n",
    "    for j in range(num_samp):\n",
    "        temp.extend(d)\n",
    "    temp.extend(d[:remainder])\n",
    "    \n",
    "    data_new.append(temp)\n",
    "\n",
    "print(\"Finished converting and padding data\")\n",
    "\n",
    "#dx = [data_new, labels]\n",
    "#dx = np.swapaxes(dx, 0, 1)\n",
    "\n",
    "#split2 = 10 / 90\n",
    "#train_val, test = sklearn.model_selection.train_test_split(dx, test_size=0.10, random_state=42)\n",
    "#train, val = sklearn.model_selection.train_test_split(train_val, test_size=split2)\n",
    "pre_split = pd.DataFrame(data_new)\n",
    "training_data, eval_data, training_labels, eval_labels = split(pre_split, labels, .2)\n",
    "train_data, test_data, train_labels, test_labels = split(training_data, training_labels, .25)\n",
    "\n",
    "print(\"Split Complete! Train Size:\", train_data.shape, \"Validation Size:\", eval_data.shape, \"Test Size:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "banned-wireless",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2968, 173)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#pre_split.head\n",
    "print(pre_split.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "whole-factory",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data, labels, size):\n",
    "    train_ndarray, test_ndarray, train_label_nd, test_label_nd = train_test_split(data, labels, test_size = size, random_state = 42)\n",
    "    d_train = pd.DataFrame(train_ndarray)\n",
    "    d_test = pd.DataFrame(test_ndarray)\n",
    "    l_train = pd.DataFrame(train_label_nd)\n",
    "    l_test = pd.DataFrame(test_label_nd)\n",
    "    return d_train, d_test, train_label_nd, test_label_nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bearing-surface",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e03d3f955296>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Rotate all on axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "# Rotate all on axes\n",
    "train = np.swapaxes(train, 0, 1)\n",
    "val = np.swapaxes(val, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "tested-vacuum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>86123</th>\n",
       "      <th>86124</th>\n",
       "      <th>86125</th>\n",
       "      <th>86126</th>\n",
       "      <th>86127</th>\n",
       "      <th>86128</th>\n",
       "      <th>86129</th>\n",
       "      <th>86130</th>\n",
       "      <th>86131</th>\n",
       "      <th>86132</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.626539</td>\n",
       "      <td>23.390087</td>\n",
       "      <td>19.426838</td>\n",
       "      <td>14.432089</td>\n",
       "      <td>0.898856</td>\n",
       "      <td>-14.858397</td>\n",
       "      <td>-27.177113</td>\n",
       "      <td>-37.953362</td>\n",
       "      <td>-31.702953</td>\n",
       "      <td>-38.369938</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.219558</td>\n",
       "      <td>21.787386</td>\n",
       "      <td>36.240211</td>\n",
       "      <td>34.810318</td>\n",
       "      <td>27.006645</td>\n",
       "      <td>31.055195</td>\n",
       "      <td>25.510529</td>\n",
       "      <td>14.626539</td>\n",
       "      <td>23.390087</td>\n",
       "      <td>19.426838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-72.245804</td>\n",
       "      <td>-58.438854</td>\n",
       "      <td>-5.313781</td>\n",
       "      <td>1.269375</td>\n",
       "      <td>0.966032</td>\n",
       "      <td>1.326349</td>\n",
       "      <td>1.495742</td>\n",
       "      <td>2.079146</td>\n",
       "      <td>3.168158</td>\n",
       "      <td>1.657128</td>\n",
       "      <td>...</td>\n",
       "      <td>-135.508057</td>\n",
       "      <td>-139.348083</td>\n",
       "      <td>-136.562988</td>\n",
       "      <td>-139.832336</td>\n",
       "      <td>-136.977127</td>\n",
       "      <td>-140.374237</td>\n",
       "      <td>-138.512329</td>\n",
       "      <td>-143.202759</td>\n",
       "      <td>-140.010498</td>\n",
       "      <td>-143.028336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70.675308</td>\n",
       "      <td>51.611614</td>\n",
       "      <td>21.229004</td>\n",
       "      <td>-9.737505</td>\n",
       "      <td>-9.156812</td>\n",
       "      <td>-7.260016</td>\n",
       "      <td>-11.004324</td>\n",
       "      <td>-17.283920</td>\n",
       "      <td>-79.607071</td>\n",
       "      <td>-108.711838</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.260016</td>\n",
       "      <td>-11.004324</td>\n",
       "      <td>-17.283920</td>\n",
       "      <td>-79.607071</td>\n",
       "      <td>-108.711838</td>\n",
       "      <td>-95.857849</td>\n",
       "      <td>-78.948616</td>\n",
       "      <td>-56.688427</td>\n",
       "      <td>-75.957779</td>\n",
       "      <td>-78.550049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-66.979813</td>\n",
       "      <td>-77.862198</td>\n",
       "      <td>-84.822495</td>\n",
       "      <td>-70.189697</td>\n",
       "      <td>-45.930717</td>\n",
       "      <td>-24.283543</td>\n",
       "      <td>-66.367439</td>\n",
       "      <td>-87.631554</td>\n",
       "      <td>-74.259201</td>\n",
       "      <td>-72.451195</td>\n",
       "      <td>...</td>\n",
       "      <td>-86.178391</td>\n",
       "      <td>-58.487511</td>\n",
       "      <td>-23.321863</td>\n",
       "      <td>-43.780670</td>\n",
       "      <td>-73.269028</td>\n",
       "      <td>-56.399788</td>\n",
       "      <td>-34.723007</td>\n",
       "      <td>-66.979813</td>\n",
       "      <td>-77.862198</td>\n",
       "      <td>-84.822495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-18.285852</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.160834</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.240053</td>\n",
       "      <td>-38.467331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 86133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0          1          2          3          4          5      \\\n",
       "0  14.626539  23.390087  19.426838  14.432089   0.898856 -14.858397   \n",
       "1 -72.245804 -58.438854  -5.313781   1.269375   0.966032   1.326349   \n",
       "2  70.675308  51.611614  21.229004  -9.737505  -9.156812  -7.260016   \n",
       "3 -66.979813 -77.862198 -84.822495 -70.189697 -45.930717 -24.283543   \n",
       "4   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "\n",
       "       6          7          8           9      ...       86123       86124  \\\n",
       "0 -27.177113 -37.953362 -31.702953  -38.369938  ...   -2.219558   21.787386   \n",
       "1   1.495742   2.079146   3.168158    1.657128  ... -135.508057 -139.348083   \n",
       "2 -11.004324 -17.283920 -79.607071 -108.711838  ...   -7.260016  -11.004324   \n",
       "3 -66.367439 -87.631554 -74.259201  -72.451195  ...  -86.178391  -58.487511   \n",
       "4   0.000000   0.000000   0.000000  -18.285852  ...   -1.160834    0.000000   \n",
       "\n",
       "        86125       86126       86127       86128       86129       86130  \\\n",
       "0   36.240211   34.810318   27.006645   31.055195   25.510529   14.626539   \n",
       "1 -136.562988 -139.832336 -136.977127 -140.374237 -138.512329 -143.202759   \n",
       "2  -17.283920  -79.607071 -108.711838  -95.857849  -78.948616  -56.688427   \n",
       "3  -23.321863  -43.780670  -73.269028  -56.399788  -34.723007  -66.979813   \n",
       "4    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "        86131       86132  \n",
       "0   23.390087   19.426838  \n",
       "1 -140.010498 -143.028336  \n",
       "2  -75.957779  -78.550049  \n",
       "3  -77.862198  -84.822495  \n",
       "4   -6.240053  -38.467331  \n",
       "\n",
       "[5 rows x 86133 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf = pd.DataFrame()\n",
    "vdf = pd.DataFrame()\n",
    "\n",
    "for i in range(len(train[0])):\n",
    "    tdf[i] = train[0][i]\n",
    "for i in range(len(val[0])):\n",
    "    vdf[i] = val[0][i]\n",
    "    \n",
    "tdf = np.swapaxes(tdf, 0, 1)\n",
    "vdf = np.swapaxes(vdf, 0, 1)\n",
    "\n",
    "tdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failing-paris",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/common/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/conda/envs/common/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "##pipeline = sklearn.pipeline.make_pipeline(sklearn.ensemble.RandomForestClassifier(n_estimators=2500, max_depth=None,random_state=0))\n",
    "logistic_C_test = LogisticRegressionCV(random_state=0, max_iter=30000,Cs = 12).fit(train_data,train_labels)\n",
    "\n",
    "print(logistic_C_test.score(test_data, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suitable-prospect",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_C_test = LogisticRegressionCV(random_state=0, max_iter=30000,Cs = 8).fit(train_data,train_labels)\n",
    "\n",
    "print(logistic_C_test.score(test_data, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-candidate",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_C_test = LogisticRegressionCV(random_state=0, max_iter=30000,Cs = 10).fit(train_data,train_labels)\n",
    "\n",
    "print(logistic_C_test.score(test_data, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-czech",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_C_test = LogisticRegressionCV(random_state=0, max_iter=30000,Cs = 5).fit(train_data,train_labels)\n",
    "\n",
    "print(logistic_C_test.score(test_data, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-rider",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_C_test = LogisticRegressionCV(random_state=0, max_iter=30000,Cs = 15).fit(train_data,train_labels)\n",
    "\n",
    "print(logistic_C_test.score(test_data, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-staff",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_test = BaggingClassifier(n_estimators=100,random_state=0)\n",
    "bagging_test.fit(train_data,train_labels)\n",
    "print(bagging_test.score(test_data, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-finance",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bagging_test.score(test_data, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "median-being",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores, fit_times, _ = learning_curve(bagging_test, test_data, test_labels,return_times=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-creek",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"test\")\n",
    "\n",
    "plt.xlabel(\"Training examples\")\n",
    "plt.ylabel(\"Score\")\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "plt.grid()\n",
    "\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                 color=\"r\")\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "         label=\"Training score\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "         label=\"Cross-validation score\")\n",
    "\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "trained-fight",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4e9b4625afa2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mGRB_mse_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mGRB_mse_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGRB_mse_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/common/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    504\u001b[0m         n_stages = self._fit_stages(\n\u001b[1;32m    505\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m             sample_weight_val, begin_at_stage, monitor)\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/common/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    561\u001b[0m             raw_predictions = self._fit_stage(\n\u001b[1;32m    562\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m                 random_state, X_csc, X_csr)\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/common/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m--> 215\u001b[0;31m                      check_input=False)\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/common/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1252\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/common/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    387\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "GRB_mse_test = GradientBoostingClassifier(n_estimators=1000, max_depth=1, random_state=0)\n",
    "GRB_mse_test.fit(train_data,train_labels)\n",
    "print(GRB_mse_test.score(test_data, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-headquarters",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = sklearn.linear_model.SGDClassifier()\n",
    "clf.fit(train_data,train_labels)\n",
    "\n",
    "print(clf.score(test_data,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-happiness",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
